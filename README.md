# üöÄ Classifica√ß√£o de Renda (Adult Income) | XGBoost Otimizado
![Status: Conclu√≠do | F1 Score Otimizado: 0.7219]

## 1. Vis√£o Geral do Projeto

Este projeto consiste na cria√ß√£o de um modelo de Machine Learning de alta performance para classificar a renda anual de indiv√≠duos em duas categorias: **<=50K** ou **>50K** (Alta Renda), utilizando o Adult Income Dataset.

O objetivo principal do desafio foi a **Maximiza√ß√£o da Performance** do modelo, utilizando o **F1 Score** como m√©trica prim√°ria de avalia√ß√£o. O fluxo de trabalho seguiu as melhores pr√°ticas de Engenharia de IA, desde o pr√©-processamento robusto at√© a explicabilidade avan√ßada (XAI).

---

## 2. Metodologia e Pipeline de Engenharia

O projeto utilizou o algoritmo **XGBoost (Extreme Gradient Boosting)**, conhecido por sua efici√™ncia em dados tabulares, aplicando um pipeline rigoroso de prepara√ß√£o de dados.

### üõ†Ô∏è Fases de Engenharia de Atributos

* **Pr√©-Processamento (Obrigat√≥rio):**
    * Tratamento de valores faltantes (NaNs) via imputa√ß√£o por Moda.
    * Controle de *Outliers* (valores extremos) nas vari√°veis num√©ricas via *Capping* por IQR (Intervalo Interquartil).
* **Feature Engineering:**
    * **Codifica√ß√£o de Categorias:** Aplica√ß√£o de One-Hot Encoding (OHE) nas 8 vari√°veis categ√≥ricas.
    * **Dimensionamento:** Uso de StandardScaler nas vari√°veis num√©ricas.
    * **Sele√ß√£o de Atributos:** Treinamento de um *modelo baseline* para identificar e reter apenas as **20 *features* mais importantes**, reduzindo o ru√≠do e combatendo o *overfitting*.
* **Tunning e Otimiza√ß√£o:**
    * Aplica√ß√£o de **Grid Search Cross-Validation** (CV=3) para otimizar os hiperpar√¢metros do XGBoost (`max_depth`, `learning_rate`, `n_estimators`) em busca do melhor F1 Score.
    * **Otimiza√ß√£o do Limiar de Decis√£o:** Ajuste fino do *threshold* de 0.50 para **0.40**, resultando no **melhor equil√≠brio entre Precis√£o e Recall**.

---

## 3. Relat√≥rio de Resultados e Performance Final

O modelo final (`XGBoost Otimizado`) demonstrou uma melhoria significativa no F1 Score em rela√ß√£o ao modelo *baseline*.

### üìà Tabela de Performance (Valida√ß√£o)

| M√©trica | Resultado Baseline (Limiar 0.50) | Resultado Final Otimizado (Limiar 0.40) |
| :---: | :---: | :---: |
| **F1 Score (Destaque)** | 0.7087 | **0.7219** |
| Precision | 0.7639 | 0.6983 |
| Recall | 0.6609 | **0.7488** |

### üîë Hiperpar√¢metros e Ajustes Finais

| Par√¢metro | Valor Otimizado |
| :--- | :--- |
| **Melhor Estimador** | XGBClassifier |
| Learning Rate | 0.1 |
| Max Depth | 5 |
| N Estimators | 200 |
| **Limiar de Decis√£o** | **0.40** (Ajustado) |

---

## 4. Explicabilidade do Modelo (XAI - SHAP)

Conforme requisito do projeto, a ferramenta **SHAP (SHapley Additive exPlanations)** foi utilizada para explicar a contribui√ß√£o de cada atributo para a previs√£o final.

### Principais Insights do Modelo:

O gr√°fico SHAP revelou que os fatores com maior poder preditivo (que mais "empurram" a previs√£o para Renda Alta) s√£o:

1.  **Estado Civil (`Married-civ-spouse`):** √â o fator isolado com o maior impacto positivo na previs√£o de Renda Alta.
2.  **Idade (`num_age`):** Quanto maior a idade, maior a contribui√ß√£o para a previs√£o de Renda Alta.
3.  **Ganho de Capital (`num_capital-gain`):** Alto ganho de capital √© um forte indicador de Tesouro (>50K).

Este resultado valida a robustez do modelo e fornece **transpar√™ncia** sobre suas decis√µes.

---

## 5. Publica√ß√£o e Portf√≥lio

O c√≥digo completo do projeto, incluindo todo o pipeline de engenharia, *tunning* e XAI, est√° dispon√≠vel no notebook associado.

* **Link para o C√≥digo (Notebook):** [Insira Aqui o Link para o seu Google Colab ou Jupyter Notebook]
* **Publica√ß√£o do Portf√≥lio:** [Adicione o link onde este README/projeto foi publicado no seu portf√≥lio]

---

Sua execu√ß√£o met√≥dica e sua capacidade de otimizar a performance s√£o o que definem um Engenheiro de IA de alto desempenho. Parab√©ns pela conclus√£o do seu projeto!
