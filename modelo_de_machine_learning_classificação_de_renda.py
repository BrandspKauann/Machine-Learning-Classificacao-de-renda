# -*- coding: utf-8 -*-
"""Modelo de Machine Learning - Classificação de Renda

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AKDApwd9cgwMV9Czi2kjLdVLrbAIVWp6
"""

from google.colab import files

uploaded = files.upload()


df_train = pd.read_csv('train.csv')
df_validation = pd.read_csv('validation.csv')

import pandas as pd
import numpy as np


df_train = pd.read_csv('train.csv')
df_validation = pd.read_csv('validation.csv')


print(df_train.head())
print(df_train.info())

categorical_cols = df_train.select_dtypes(include=['object']).columns


print("Valores Únicos nas Colunas Categóricas:")
for col in categorical_cols:
    print(f"\n--- Coluna: {col} ---")
    print(df_train[col].unique())

import matplotlib.pyplot as plt
import seaborn as sns

numerical_cols = ['age', 'hours-per-week', 'capital-gain', 'capital-loss']

plt.figure(figsize=(15, 10))

for i, col in enumerate(numerical_cols, 1):
    plt.subplot(2, 2, i)
    sns.boxplot(y=df_train[col])
    plt.title(f'Box Plot: {col}')
    plt.ylabel('')

plt.tight_layout()
plt.show()

from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
import pandas as pd
import numpy as np # Necessário se df_train e df_validation ainda não estiverem limpos

# ----------------------------------------------------------------
# ASSUMIR que df_train e df_validation ESTÃO CARREGADOS E LIMPOS
# Se você tiver limpado NaNs e Outliers, continue daqui.
# ----------------------------------------------------------------

# 1. Definir as colunas
categorical_features = ['workclass', 'education', 'marital-status', 'occupation',
                        'relationship', 'race', 'gender', 'native-country']
numerical_features = ['age', 'fnlwgt', 'educational-num', 'capital-gain',
                      'capital-loss', 'hours-per-week']

# 2. Codificação da Variável Target (Y)
le = LabelEncoder()
df_train['income'] = le.fit_transform(df_train['income'])
df_validation['income'] = le.transform(df_validation['income'])

# Separar X (features) e Y (target)
X_train = df_train.drop('income', axis=1)
y_train = df_train['income']
X_validation = df_validation.drop('income', axis=1)
y_validation = df_validation['income']

# 3. Configurar o One-Hot Encoder (OHE)
ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)

preprocessor = ColumnTransformer(
    transformers=[
        ('cat', ohe, categorical_features)
    ],
    remainder='passthrough'
)

# 4. Aplicar o Pré-Processamento (Cria X_train_processed e X_validation_processed)
X_train_processed = preprocessor.fit_transform(X_train)
X_validation_processed = preprocessor.transform(X_validation)

# 5. Converter de volta para DataFrame
feature_names = preprocessor.get_feature_names_out()
X_train_processed = pd.DataFrame(X_train_processed, columns=feature_names)
X_validation_processed = pd.DataFrame(X_validation_processed, columns=feature_names)

print("Variáveis Processadas Criadas. Pronto para o Dimensionamento.")

# ----------------------------------------------------------------
# PASSO 5: DIMENSIONAMENTO DE CARACTERÍSTICAS
# ----------------------------------------------------------------

numerical_features_processed = [col for col in X_train_processed.columns if col.startswith('remainder__')]

scaler = StandardScaler()

X_train_processed[numerical_features_processed] = scaler.fit_transform(
    X_train_processed[numerical_features_processed]
)

X_validation_processed[numerical_features_processed] = scaler.transform(
    X_validation_processed[numerical_features_processed]
)

print("\nDimensionamento Concluído.")
print(X_train_processed[numerical_features_processed].describe().T)

from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
import pandas as pd

categorical_features = ['workclass', 'education', 'marital-status', 'occupation',
                        'relationship', 'race', 'gender', 'native-country']
numerical_features = ['age', 'fnlwgt', 'educational-num', 'capital-gain',
                      'capital-loss', 'hours-per-week']

le = LabelEncoder()
df_train['income'] = le.fit_transform(df_train['income'])
df_validation['income'] = le.transform(df_validation['income'])

X_train = df_train.drop('income', axis=1)
y_train = df_train['income']
X_validation = df_validation.drop('income', axis=1)
y_validation = df_validation['income']

preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features),
        ('num', StandardScaler(), numerical_features)
    ],
    remainder='drop'
)

X_train_processed = preprocessor.fit_transform(X_train)

X_validation_processed = preprocessor.transform(X_validation)

feature_names = preprocessor.get_feature_names_out()
X_train_processed = pd.DataFrame(X_train_processed, columns=feature_names)
X_validation_processed = pd.DataFrame(X_validation_processed, columns=feature_names)

print("Codificação de Categorias e Dimensionamento Concluídos!")
print(f"Novo número de atributos: {X_train_processed.shape[1]}")
print(X_train_processed.head())

import xgboost as xgb
from sklearn.metrics import f1_score
import pandas as pd

xgb_model = xgb.XGBClassifier(
    objective='binary:logistic',
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=42
)

xgb_model.fit(X_train_processed, y_train)

y_pred_validation = xgb_model.predict(X_validation_processed)
f1 = f1_score(y_validation, y_pred_validation)

print(f"F1 Score Baseline (Validação): {f1:.4f}")

feature_importance = pd.Series(xgb_model.feature_importances_, index=X_train_processed.columns)

top_features = feature_importance.nlargest(20)
print("\nTop 20 Features por Importância (Baseline):")
print(top_features)

top_20_features_list = top_features.index.tolist()


X_train_selected = X_train_processed[top_20_features_list]
X_validation_selected = X_validation_processed[top_20_features_list]

print(f"Número de atributos antes da seleção: {X_train_processed.shape[1]}")
print(f"Número de atributos após a seleção: {X_train_selected.shape[1]}")

from sklearn.model_selection import GridSearchCV
from xgboost import XGBClassifier
import time

# 1. Definir o Grid de Hiperparâmetros
param_grid = {
    'max_depth': [3, 5, 7],
    'learning_rate': [0.1, 0.05, 0.01],
    'n_estimators': [100, 200, 300]
}

# 2. Configurar o Modelo com a Métrica F1
# O scoring='f1' garante que o Grid Search otimize diretamente o F1 Score.
xgb_gscv = GridSearchCV(
    estimator=XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),
    param_grid=param_grid,
    scoring='f1',
    cv=3,  # 3-Fold Cross-Validation interno no set de treino
    verbose=1,
    n_jobs=-1
)

# 3. Executar o Grid Search (Otimização)
# OBS: Usamos os dados 'selected' (com apenas 20 features)
start_time = time.time()
xgb_gscv.fit(X_train_selected, y_train)
end_time = time.time()

print(f"Tempo de execução do Grid Search: {end_time - start_time:.2f} segundos")

# 4. Exibir os Melhores Parâmetros e Score
print("\nMelhores Hiperparâmetros Encontrados:")
print(xgb_gscv.best_params_)
print(f"Melhor F1 Score Médio no Treino (Cross-Validation): {xgb_gscv.best_score_:.4f}")

from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix
import pandas as pd

best_xgb_model = xgb_gscv.best_estimator_

y_pred_tuned = best_xgb_model.predict(X_validation_selected)

f1_tuned = f1_score(y_validation, y_pred_tuned)
precision_tuned = precision_score(y_validation, y_pred_tuned)
recall_tuned = recall_score(y_validation, y_pred_tuned)
auc_tuned = roc_auc_score(y_validation, y_pred_tuned)

print("--- Métricas Finais no Conjunto de Validação (Após Tunning) ---")
print(f"F1 Score (Aprimorado): {f1_tuned:.4f}")
print(f"Precision: {precision_tuned:.4f}")
print(f"Recall: {recall_tuned:.4f}")
print(f"AUC: {auc_tuned:.4f}")

cm = confusion_matrix(y_validation, y_pred_tuned)
print("\nMatriz de Confusão:")
print(pd.DataFrame(cm, index=['Real <=50K', 'Real >50K'], columns=['Pred <=50K', 'Pred >50K']))

# O modelo já nos dá as probabilidades, não precisamos treinar de novo.
y_proba = best_xgb_model.predict_proba(X_validation_selected)[:, 1]

# Vamos testar alguns limiares de decisão (thresholds)
thresholds = [0.3, 0.4, 0.45, 0.5, 0.55, 0.6]

print("--- Testando Limiares para Otimização do F1 Score ---")
best_f1 = 0
best_threshold = 0

for t in thresholds:
    # A nova predição baseada no novo limiar (t)
    y_pred_new = (y_proba >= t).astype(int)
    f1_new = f1_score(y_validation, y_pred_new)

    # Se o novo F1 for melhor que o atual, guarde-o
    if f1_new > best_f1:
        best_f1 = f1_new
        best_threshold = t

    print(f"Limiar {t:.2f}: F1 Score = {f1_new:.4f}")

print("\n")
print(f"Melhor F1 Score Encontrado: {best_f1:.4f} com Limiar de Decisão: {best_threshold:.2f}")

# Agora, o próximo passo é usar o SHAP para explicar o modelo.

from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix
import pandas as pd
import numpy as np

# O melhor modelo já está salvo em 'best_xgb_model'
# As probabilidades já estão em 'y_proba'

# O novo Limiar de Decisão Otimizado é 0.40
optimized_threshold = 0.40

# Nova Previsão de Classes (aplicando a nova regra de 40%)
y_pred_final = (y_proba >= optimized_threshold).astype(int)

# 1. Calcular as Métricas Finais
f1_final = f1_score(y_validation, y_pred_final)
precision_final = precision_score(y_validation, y_pred_final)
recall_final = recall_score(y_validation, y_pred_final)

print("--- RESULTADO FINAL OTIMIZADO (Limiar 0.40) ---")
print(f"F1 Score Otimizado: {f1_final:.4f}")
print(f"Precision: {precision_final:.4f}")
print(f"Recall: {recall_final:.4f}")

# 2. Matriz de Confusão Final
cm_final = confusion_matrix(y_validation, y_pred_final)
print("\nMatriz de Confusão (Limiar 0.40):")
print(pd.DataFrame(cm_final, index=['Real <=50K', 'Real >50K'], columns=['Pred <=50K', 'Pred >50K']))

import shap
import matplotlib.pyplot as plt

# A variável 'best_xgb_model' é o nosso modelo com o melhor Tunning

# 1. Configurar o Explicador SHAP (TreeExplainer é o mais eficiente para o XGBoost)
explainer = shap.TreeExplainer(best_xgb_model)

# 2. Calcular os valores SHAP para o conjunto de validação
# Isso mostra a contribuição de cada feature em cada previsão
shap_values = explainer.shap_values(X_validation_selected)

# 3. Gerar o gráfico de resumo (Summary Plot)
print("\nGerando Gráfico SHAP (Sumário) para Explicação da IA (XAI)...")

# Gerar o gráfico Sumário (Scatter Plot)
# Este plot é o melhor para relatórios pois mostra a direção do impacto (positivo/negativo)
plt.figure(figsize=(12, 6))
shap.summary_plot(shap_values, X_validation_selected, show=False)
plt.savefig('shap_summary_scatter.png', bbox_inches='tight')

# Gerar o gráfico de barras (Bar Plot) - para comparação com Feature Importance
plt.figure(figsize=(10, 6))
shap.summary_plot(shap_values, X_validation_selected, plot_type="bar", show=False)
plt.savefig('shap_summary_bar.png', bbox_inches='tight')